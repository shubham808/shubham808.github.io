---
layout: post
title: Week 6
---

This week we refined and completed IterativeMachine class as a mixin.
We focused on Perceptron as an example to see how things would actually look like
when we implement our idea.<br>
The flow begins when the user calls "train" for an Iterative machine which will be perceptron for us.<br>
the train method is implemented in CMachine and calls train_machine with the provided data pointer.<br>
The mixin has 3 data members: m_current_iteration, m_max_iteration and m_complete.<br>
The train_machine is implemented in the subclasses and implements the training process for an algorithm.<br>
In IterativeMachine we implement train_machine for subclasses in the mixin.<br>
Instead the subclasses will now implement 3 methods:<br>
<br>
init_model: The subclass can initialize its members here along with any other ops that need to be done
before training begins.<br>
<br>
iteration: The actual iteration is implemented here.<br>
<br>
end_training: this is an optional method which can be used for some additional error handling and/or cleaning states of members.<br>
<br>
Data between the three methods is shared with the help of data members of subclass. Doing this has an additional advantage.<br>
We are forced to write code that uses already present data members like m_w(weights), bias of CLinearMachine.<br>
The state is hence being automatically updated every iteration. This keeps the model "current" during a paused state.<br>
<br>
The train_machine calls init_model with the features data pointer. This initializes the model parameters.<br>
next it calls continue_train. This is the new element of our class. In continue_train we have the while loop 
that runs till convergence or maximum iteration. the loop calls the iteration method of subclass again and again.<br>
<br>
When the user decides to prematurely cancel computation control is returned to main. The user can perform what ever is need now.
For eg he can serialize the incomplete model for comparisions, he can apply the model or some test data, and then simply call 
continue_train to resume training of the model.<br>
<br>
The pull request includes a test in Perceptron that shows the genral idea of how things work now.
<br>
### Contributions

[Iterative Machine](https://github.com/shogun-toolbox/shogun/pull/4335)
